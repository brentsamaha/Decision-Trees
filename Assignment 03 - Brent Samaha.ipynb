{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3 - Brent Samaha "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from scipy.stats import randint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1. Read in data - split 70/30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading in dataset\n",
    "spotify_data = pd.read_csv(\"dataset-of-00s.csv\")\n",
    "\n",
    "#Dropping unwanted columns\n",
    "spotify_data = spotify_data.drop(['track', 'artist', 'uri'], axis=1)\n",
    "\n",
    "#Splitting dataset into 70/30 train/validation datasets\n",
    "train_data, val_data = train_test_split(spotify_data, train_size = 0.7, random_state = 13)\n",
    "\n",
    "#Identifying target variable as y & predictors as x for the train/validation datasets\n",
    "y_train = train_data.target\n",
    "x_train = train_data.iloc[:, :-1]\n",
    "\n",
    "y_val = val_data.target\n",
    "x_val = val_data.iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2. Train a decision tree & report AUCs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"max_depth\":range(2, 8), \"min_samples_leaf\": range(5, 55, 5), \"min_samples_split\": range(10, 110, 5)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = GridSearchCV(DecisionTreeClassifier(), params, n_jobs=4, scoring = \"roc_auc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=DecisionTreeClassifier(), n_jobs=4,\n",
       "             param_grid={'max_depth': range(2, 8),\n",
       "                         'min_samples_leaf': range(5, 55, 5),\n",
       "                         'min_samples_split': range(10, 110, 5)},\n",
       "             scoring='roc_auc')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtree.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_prob = dtree.predict_proba(x_train)\n",
    "\n",
    "y_val_prob = dtree.predict_proba(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training dataset auc is  0.9081380050466781\n"
     ]
    }
   ],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(y_train, y_train_prob[:,1], pos_label = 1)\n",
    "train_auc = metrics.auc(fpr, tpr)\n",
    "print(\"The training dataset auc is \" , train_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation AUC is  0.8828783732244829\n"
     ]
    }
   ],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(y_val, y_val_prob[:,1], pos_label = 1)\n",
    "val_auc = metrics.auc(fpr, tpr)\n",
    "print(\"The validation AUC is \" , val_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3. Train a random forest & report AUCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"max_depth\":range(2, 8), \"min_samples_leaf\": range(5, 55, 5), \"min_samples_split\": range(10, 110, 5),\n",
    "          \"max_samples\":[0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4], \"max_features\": [2, 3, 4, 5, 6],\n",
    "          \"n_estimators\": [100, 150, 200, 250, 300, 350, 400]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "rforest = RandomizedSearchCV(RandomForestClassifier(), params, n_jobs=4, scoring = \"roc_auc\", n_iter = 300,\n",
    "                             random_state = 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=RandomForestClassifier(), n_iter=300, n_jobs=4,\n",
       "                   param_distributions={'max_depth': range(2, 8),\n",
       "                                        'max_features': [2, 3, 4, 5, 6],\n",
       "                                        'max_samples': [0.1, 0.15, 0.2, 0.25,\n",
       "                                                        0.3, 0.35, 0.4],\n",
       "                                        'min_samples_leaf': range(5, 55, 5),\n",
       "                                        'min_samples_split': range(10, 110, 5),\n",
       "                                        'n_estimators': [100, 150, 200, 250,\n",
       "                                                         300, 350, 400]},\n",
       "                   random_state=13, scoring='roc_auc')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rforest.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_prob = rforest.predict_proba(x_train)\n",
    "\n",
    "y_val_prob = rforest.predict_proba(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training dataset auc is  0.9313755275900217\n"
     ]
    }
   ],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(y_train, y_train_prob[:,1], pos_label = 1)\n",
    "train_auc = metrics.auc(fpr, tpr)\n",
    "print(\"The training dataset auc is \" , train_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation AUC is  0.9122401148287876\n"
     ]
    }
   ],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(y_val, y_val_prob[:,1], pos_label = 1)\n",
    "val_auc = metrics.auc(fpr, tpr)\n",
    "print(\"The validation AUC is \" , val_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4. Train a gradient boosting model & report AUCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"max_depth\":range(2, 6), \"min_samples_leaf\": range(5, 55, 5), \"min_samples_split\": range(10, 110, 5),\n",
    "          \"subsample\":[0.6, 0.7, 0.8], \"max_features\": [2, 3, 4, 5, 6],\n",
    "          \"n_estimators\": [50, 100, 150, 200], \"learning_rate\": [0.1, 0.2, 0.3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradboost = RandomizedSearchCV(GradientBoostingClassifier(), params, n_jobs=4, scoring = \"roc_auc\", n_iter = 300,\n",
    "                               random_state = 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=GradientBoostingClassifier(), n_iter=300, n_jobs=4,\n",
       "                   param_distributions={'learning_rate': [0.1, 0.2, 0.3],\n",
       "                                        'max_depth': range(2, 6),\n",
       "                                        'max_features': [2, 3, 4, 5, 6],\n",
       "                                        'min_samples_leaf': range(5, 55, 5),\n",
       "                                        'min_samples_split': range(10, 110, 5),\n",
       "                                        'n_estimators': [50, 100, 150, 200],\n",
       "                                        'subsample': [0.6, 0.7, 0.8]},\n",
       "                   random_state=13, scoring='roc_auc')"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradboost.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_prob = gradboost.predict_proba(x_train)\n",
    "\n",
    "y_val_prob = gradboost.predict_proba(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training dataset auc is  0.9860092740285524\n"
     ]
    }
   ],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(y_train, y_train_prob[:,1], pos_label = 1)\n",
    "train_auc = metrics.auc(fpr, tpr)\n",
    "print(\"The training dataset auc is \" , train_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation AUC is  0.9306962139485023\n"
     ]
    }
   ],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(y_val, y_val_prob[:,1], pos_label = 1)\n",
    "val_auc = metrics.auc(fpr, tpr)\n",
    "print(\"The validation AUC is \" , val_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5. Train a model with XGBoost & report AUCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'max_depth': range(2, 6), \n",
    "          'n_estimators': [50, 100, 150, 200, 250, 300],\n",
    "          'subsample': [0.6, 0.7, 0.8],\n",
    "          'colsample_bytree': [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.6, 0.7, 0.8, 1], \n",
    "          'colsample_bynode': [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.6, 0.7, 0.8, 1],\n",
    "          'gamma': [0, 5, 10, 15, 20], \n",
    "          'learning_rate': [0.05, 0.1, 0.15, 0.2, 0.25, 0.3],\n",
    "          'lambda': [0.1, 0.25, 0.5, 0.75, 1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbmodel = RandomizedSearchCV(xgb.XGBClassifier(use_label_encoder = False, eval_metric = \"logloss\"), \n",
    "                              params, n_jobs=4, scoring = \"roc_auc\", n_iter = 300, random_state = 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=XGBClassifier(eval_metric='logloss',\n",
       "                                           use_label_encoder=False),\n",
       "                   n_iter=300, n_jobs=4,\n",
       "                   param_distributions={'colsample_bynode': [0.1, 0.15, 0.2,\n",
       "                                                             0.25, 0.3, 0.35,\n",
       "                                                             0.4, 0.45, 0.5,\n",
       "                                                             0.6, 0.7, 0.8, 1],\n",
       "                                        'colsample_bytree': [0.1, 0.15, 0.2,\n",
       "                                                             0.25, 0.3, 0.35,\n",
       "                                                             0.4, 0.45, 0.5,\n",
       "                                                             0.6, 0.7, 0.8, 1],\n",
       "                                        'gamma': [0, 5, 10, 15, 20],\n",
       "                                        'lambda': [0.1, 0.25, 0.5, 0.75, 1],\n",
       "                                        'learning_rate': [0.05, 0.1, 0.15, 0.2,\n",
       "                                                          0.25, 0.3],\n",
       "                                        'max_depth': range(2, 6),\n",
       "                                        'n_estimators': [50, 100, 150, 200, 250,\n",
       "                                                         300],\n",
       "                                        'subsample': [0.6, 0.7, 0.8]},\n",
       "                   random_state=13, scoring='roc_auc')"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbmodel.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subsample': 0.6,\n",
       " 'n_estimators': 250,\n",
       " 'max_depth': 4,\n",
       " 'learning_rate': 0.05,\n",
       " 'lambda': 1,\n",
       " 'gamma': 0,\n",
       " 'colsample_bytree': 0.7,\n",
       " 'colsample_bynode': 0.4}"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbmodel.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_prob = xgbmodel.predict_proba(x_train)\n",
    "\n",
    "y_val_prob = xgbmodel.predict_proba(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training dataset auc is  0.9682290403734238\n"
     ]
    }
   ],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(y_train, y_train_prob[:,1], pos_label = 1)\n",
    "train_auc = metrics.auc(fpr, tpr)\n",
    "print(\"The training dataset auc is \" , train_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation AUC is  0.9308018688024408\n"
     ]
    }
   ],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(y_val, y_val_prob[:,1], pos_label = 1)\n",
    "val_auc = metrics.auc(fpr, tpr)\n",
    "print(\"The validation AUC is \" , val_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From the four models ran on the dataset, the best performing model was the XGBoost model. The XGBoost model had a training AUC of .968 and a validation AUC of .9308. The second best model, the Gradient Boosting Model had a training AUC of .986, but a lower validation AUC of .9306. The XGBoost & Gradient Boosting validation AUCs were close, but the XGBoost performed slightly better when making predictions off of new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 6. Find optimal probability based off of F-1 Score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using XGBoost model to find the optimal probability as it was the best performing model.\n",
    "\n",
    "prob = np.arange(.01,1,.01)\n",
    "prec = []; recall = []; acc = []; f1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "for threshold in prob:\n",
    "    \n",
    "    #using for loop to go through all values in array of .01-.99\n",
    "    #if the predicted probability is greater than the current iterable of the array, pred = 1, if less than, pred = 0\n",
    "    prediction = [1 if prob >= threshold else 0 for prob in y_train_prob[:,1]]\n",
    "    \n",
    "    #calculating metrics at each iterable in probability array; actual vs. predicted above\n",
    "    precision = metrics.precision_score(y_train, prediction)\n",
    "    rec = metrics.recall_score(y_train, prediction)\n",
    "    accuracy = metrics.accuracy_score(y_train, prediction)\n",
    "    f1score = metrics.f1_score(y_train, prediction)\n",
    "    \n",
    "    #appending metrics to their respective list\n",
    "    prec.append(precision)\n",
    "    recall.append(rec)\n",
    "    acc.append(accuracy)\n",
    "    f1.append(f1score)\n",
    "    \n",
    "#creating a dictionary to transform into a DF\n",
    "dic={'threshold':prob, 'precision':prec, 'recall':rec, 'accuracy':acc, 'F1_Score':f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>F1_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.564810</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.616058</td>\n",
       "      <td>0.721889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.601115</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.669343</td>\n",
       "      <td>0.750871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.625535</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.701703</td>\n",
       "      <td>0.769635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.645131</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.725791</td>\n",
       "      <td>0.784141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.666124</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.750122</td>\n",
       "      <td>0.799453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.994135</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.583698</td>\n",
       "      <td>0.283801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.995575</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.556204</td>\n",
       "      <td>0.197889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.97</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.527251</td>\n",
       "      <td>0.097538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.98</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.509246</td>\n",
       "      <td>0.029822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.99</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.501946</td>\n",
       "      <td>0.000976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    threshold  precision    recall  accuracy  F1_Score\n",
       "0        0.01   0.564810  0.000488  0.616058  0.721889\n",
       "1        0.02   0.601115  0.000488  0.669343  0.750871\n",
       "2        0.03   0.625535  0.000488  0.701703  0.769635\n",
       "3        0.04   0.645131  0.000488  0.725791  0.784141\n",
       "4        0.05   0.666124  0.000488  0.750122  0.799453\n",
       "..        ...        ...       ...       ...       ...\n",
       "94       0.95   0.994135  0.000488  0.583698  0.283801\n",
       "95       0.96   0.995575  0.000488  0.556204  0.197889\n",
       "96       0.97   1.000000  0.000488  0.527251  0.097538\n",
       "97       0.98   1.000000  0.000488  0.509246  0.029822\n",
       "98       0.99   1.000000  0.000488  0.501946  0.000976\n",
       "\n",
       "[99 rows x 5 columns]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability_metrics = pd.DataFrame(dic)\n",
    "probability_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "threshold    0.590000\n",
       "precision    0.928260\n",
       "recall       0.935059\n",
       "accuracy     0.931630\n",
       "f1_score     0.931647\n",
       "Name: 58, dtype: float64"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.iloc[result.f1_score.idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training precision:  0.8994683421942967\n",
      "Training recall:  0.90869140625\n",
      "Training accuracy:  0.9038929440389294\n",
      "Training F1-Score:  0.904056351712412\n"
     ]
    }
   ],
   "source": [
    "#Optimal threshold is .59\n",
    "\n",
    "pred = [1 if prob >= 0.59 else 0 for prob in y_train_prob[:,1]]\n",
    "\n",
    "#Finding metrics for training data using optimal threshold of .59\n",
    "tprec = metrics.precision_score(y_train, pred)\n",
    "trecall = metrics.recall_score(y_train, pred)\n",
    "taccuracy = metrics.accuracy_score(y_train, pred)\n",
    "tf1score = metrics.f1_score(y_train, pred)\n",
    "\n",
    "print(\"Training precision: \", tprec)\n",
    "print(\"Training recall: \", trecall)\n",
    "print(\"Training accuracy: \", taccuracy)\n",
    "print(\"Training F1-Score: \", tf1score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation precision:  0.8444444444444444\n",
      "Validation recall:  0.8558558558558559\n",
      "Validation accuracy:  0.8479001135073779\n",
      "Validation F1-Score:  0.8501118568232663\n"
     ]
    }
   ],
   "source": [
    "pred = [1 if prob >= 0.59 else 0 for prob in y_val_prob[:,1]]\n",
    "\n",
    "#Finding metrics for validation data using optimal threshold of .59\n",
    "vprec = metrics.precision_score(y_val, pred)\n",
    "vrecall = metrics.recall_score(y_val, pred)\n",
    "vaccuracy = metrics.accuracy_score(y_val, pred)\n",
    "vf1score = metrics.f1_score(y_val, pred)\n",
    "\n",
    "print(\"Validation precision: \", vprec)\n",
    "print(\"Validation recall: \", vrecall)\n",
    "print(\"Validation accuracy: \", vaccuracy)\n",
    "print(\"Validation F1-Score: \", vf1score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 7. Calculating Gini Impurity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. The dataset has 75% positive labels and 25% negative labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.375"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GI = 1 - (.75)**2 - (.25)**2\n",
    "GI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. The dataset has 90% positive labels and 10% negative labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17999999999999994"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GI = 1 - (.90)**2 - (.10)**2\n",
    "GI"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
